{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCRL for article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import sample\n",
    "import math \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 10 #Degradation threshold\n",
    "\n",
    "def state(amount):\n",
    "    new_state = []    \n",
    "    if (amount >= 0 and amount <3):\n",
    "        new_state = 0 # healthy1\n",
    "    \n",
    "    if (amount >= 3 and amount <7):\n",
    "        new_state = 1 # healthy2\n",
    "        \n",
    "    if (amount >= 7 and amount < z ):\n",
    "        new_state = 2 #healthy3 \n",
    "        \n",
    "    if (amount >= z):\n",
    "        new_state = 3 # fail\n",
    "    \n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rewardfun(degradation):\n",
    "    Reward=np.zeros((4,)+(3,))\n",
    "    Reward[: , 0] = -50\n",
    "    Reward[3,0] = -1050\n",
    "    Reward[: , 1] = -500*(degradation/z)-50\n",
    "    Reward[3,1] = -1150\n",
    "    Reward[: , 2] = -550\n",
    "    Reward[3,2] = -1550\n",
    "       \n",
    "    return Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 8\n",
    "\n",
    "def Envirenment(degradation , action):\n",
    "   \n",
    "    n2 = np.random.poisson((1-0.001)*4, 1) # number of effective shock\n",
    "    w2 = np.random.gamma(0.6, 1.2, n2) # magnitude of effective shock\n",
    "    magnitude = sum(w2)\n",
    "    next_state = 0\n",
    "    reward = 0\n",
    "    \n",
    "    if action == 0 :#do nothing\n",
    "        \n",
    "            degradation += (magnitude + 3)/a\n",
    "            next_state=state(degradation)\n",
    "            Reward=Rewardfun(degradation)\n",
    "            reward=Reward[next_state,action]\n",
    "        \n",
    "    if action == 1 : #repair\n",
    "        \n",
    "           # decay = degradation*np.random.beta(0.5, 1, 1)\n",
    "            #decay = degradation/z\n",
    "            #degradation -= decay*degradation\n",
    "            degradation = np.max((0.05, degradation))\n",
    "            decay =(np.random.gamma(degradation*degradation/2,2/(degradation),1)/z)[0]\n",
    "            degradation -= np.max((0, decay*degradation))\n",
    "            degradation = np.max((0.05, degradation))\n",
    "            degradation += (magnitude + 2.95)/a\n",
    "            next_state=state(degradation)\n",
    "            Reward=Rewardfun(degradation)\n",
    "            reward=Reward[next_state,action]\n",
    "                    \n",
    "    if action == 2 : # replace\n",
    "        \n",
    "            degradation = (magnitude + 2.85)/a\n",
    "            next_state=state(degradation)\n",
    "            Reward=Rewardfun(degradation)\n",
    "            reward=Reward[next_state,action]\n",
    "       \n",
    "    \n",
    "    return next_state , reward , degradation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pi function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_POSSIBLE_ACTIONS = [0,1,2]\n",
    "def policy_using_pi(St, pi):\n",
    "    return np.random.choice(ALL_POSSIBLE_ACTIONS, p=[pi[(St,a)] for a in ALL_POSSIBLE_ACTIONS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(current_state, pi):\n",
    "    if current_state == 3 :\n",
    "        return 2 #replace\n",
    "    else:\n",
    "        return policy_using_pi(current_state, pi)  #epsilon_soft       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episode Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA =  0.9\n",
    "def play_episode(pi):\n",
    "    #S0,A0,R1,S1,A1,R2,S2,A2,R3 ,...\n",
    "    s = 0 #it is new\n",
    "    d = 0 #it is new\n",
    "    a= choose_action(s, pi)\n",
    "    \n",
    "    #r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "    states_actions_rewards = [((s, a, 0))]\n",
    "    \n",
    "    for j in range(100 +1):\n",
    "    \n",
    "        s , r ,d  = Envirenment(d,a)\n",
    "        if (j == 100):\n",
    "            states_actions_rewards.append((s, None, r))\n",
    "        else:\n",
    "            a= choose_action(s, pi)\n",
    "            states_actions_rewards.append((s,a, r))\n",
    "            \n",
    "    \n",
    "     # calculate the returns by working backwards from the terminal state\n",
    "    G = 0\n",
    "    states_actions_returns = []\n",
    "    first = True\n",
    "    for s, a, r in reversed(states_actions_rewards):\n",
    "        \n",
    "       # the value of the terminal state is 0 by definition\n",
    "       # we should ignore the first state we encounter\n",
    "        # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            states_actions_returns.append((s, a, G))\n",
    "        G = r + GAMMA*G\n",
    "    \n",
    "    return states_actions_returns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  del sys.path[0]\n",
      "C:\\Users\\ARYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\ARYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\Users\\ARYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\ARYA\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1\n",
    "learning_rate = 1\n",
    "pi = defaultdict(lambda: 1/len(ALL_POSSIBLE_ACTIONS))\n",
    "Q = np.zeros((4, ) + (3,))\n",
    "old_Q = 0 \n",
    "\n",
    "Q[3,0]= -100000000\n",
    "Q[3,1]= -100000000\n",
    "\n",
    "returns =np.zeros((4,) + (3,))\n",
    "N = np.zeros((4 ,) + (3,))\n",
    "\n",
    "deltas = []\n",
    "\n",
    "\n",
    "for epi in range(500 +1):# Looping through episodes \n",
    "    \n",
    "    # generate an episode using pi\n",
    "    biggest_change = 0\n",
    "    states_actions_returns = play_episode(pi)\n",
    "    \n",
    "    seen_state_action_pairs = set()\n",
    "    for s, a, G in states_actions_returns:\n",
    "        # check if we have already seen s\n",
    "        # called \"first-visit\" MC policy evaluation\n",
    "    \n",
    "        state_action = (s,a)\n",
    "        \n",
    "        if state_action not in seen_state_action_pairs:\n",
    "            \n",
    "            returns[s][a] += G\n",
    "            N[s][a] +=1\n",
    "            old_Q = Q[s][a]    \n",
    "            Q[s][a] = returns[s][a] /N[s][a] # Average reward across episodes\n",
    "            \n",
    "            biggest_change = max(biggest_change, np.abs(old_Q - Q[s][a]))\n",
    "            seen_state_action_pairs.add(state_action)\n",
    "              \n",
    "            #for each s in the episode         \n",
    "            A_star = np.argmax(Q[s])# Finding the action with maximum value        \n",
    "            for a in ALL_POSSIBLE_ACTIONS: # Update action probability for s_t in policy\n",
    "                if a == A_star:\n",
    "                    pi[(s,a)] = 1 - epsilon + (epsilon / len(ALL_POSSIBLE_ACTIONS))\n",
    "                else:\n",
    "                    pi[(s,a)] = (epsilon / len(ALL_POSSIBLE_ACTIONS))\n",
    "                     \n",
    "    \n",
    "    learning_rate *= 0.99\n",
    "    epsilon *= 0.99               \n",
    "    deltas.append(biggest_change)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.39503070e+03, -3.58291120e+03, -2.08103223e+03],\n",
       "       [-8.50808535e+02, -3.00952709e+03, -3.06416498e+03],\n",
       "       [-3.91492639e+03, -1.40569272e+03, -3.51498671e+03],\n",
       "       [-1.00000000e+08, -1.00000000e+08, -1.83098324e+03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYXNV95vHvr6p61b60hJCEhYOwETZgogE8nsQO2EIQx5DHMA+2H6PxkNFkQjzOM8kkMEnM2ITY8YxjD07ChBjF2GMbEy9BxtigCIhXlhZgARJCLSGgkVC31OpN3V1dy2/+uKda1d21tEQv0q3389BP1T11quqcVlNv3XPPPdfcHRERqT2JmW6AiIjMDAWAiEiNUgCIiNQoBYCISI1SAIiI1CgFgIhIjVIAiIjUKAWAiEiNUgCIiNSo1Ew3oJLFixf7qlWrZroZIiKnlG3bth1y95Zq9U7qAFi1ahWtra0z3QwRkVOKmb08kXoaAhIRqVEKABGRGqUAEBGpUQoAEZEapQAQEalRCgARkRqlABARqVGxDIADPYN8/qFd7O3sn+mmiIictGIZAAd703zp4Tb2HT46000RETlpxTIAEhbd6nr3IiLlxTIAjCgB8goAEZGy4hkAI3sASgARkXLiHQAz2wwRkZNaPAMgDAFpD0BEpLx4BoAOAouIVBXLAEiEBNDnv4hIebEMgMIeQF67ACIiZcUzAMKtPv9FRMqLZwBoFpCISFUTCgAzm29m3zazF8xsp5m908wWmtkWM9sdbheEumZmt5tZm5ltN7MLi15nQ6i/28w2TFWnzDQLSESkmonuAfwf4Efu/lbgfGAncBOw1d1XA1vDNsAVwOrwsxG4A8DMFgK3ABcDFwG3FEJjsmkISESkuqoBYGZzgV8H7gJw92F37wauAu4O1e4Grg73rwK+6pHHgPlmtgy4HNji7l3ufgTYAqyf1N4cazMArkEgEZGyJrIH8GagE/hHM3vazL5sZrOApe5+ACDcLgn1lwOvFj2/PZSVK590WgxORKS6iQRACrgQuMPd3wEc5dhwTylWoswrlI9+stlGM2s1s9bOzs4JNK9UA7QYnIhINRMJgHag3d0fD9vfJgqEg2Foh3DbUVR/ZdHzVwD7K5SP4u53uvtad1/b0tJyPH0ZocXgRESqqxoA7v468KqZvSUUXQbsADYDhZk8G4D7wv3NwPVhNtAlQE8YInoQWGdmC8LB33WhbMro419EpLzUBOt9HPi6mdUDe4GPEYXHvWZ2A/AKcG2o+wBwJdAGDIS6uHuXmd0KPBnqfdrduyalF2MkEjoRQESkmgkFgLs/A6wt8dBlJeo6cGOZ19kEbDqeBp6IwsEGLQUhIlKezgQWEalRsQyAkdVAlQAiImXFMgA0BCQiUl0sAwANAYmIVBXLAEjokmAiIlXFMgCODQHNaDNERE5q8QwALQctIlJVPAMg3OrjX0SkvFgGgKaBiohUF8sAQBeFFxGpKpYBYKUWnhYRkVFiGQAaAhIRqS6WAaAzgUVEqotnAOhMYBGRqmIZABoCEhGpLpYBUKAhIBGR8mIZAJoFJCJSXTwDAC0FISJSTSwDIKHFQEVEqoplABQWg9NqoCIi5cUzAMKtayKoiEhZ8QwADQGJiFQ1oQAws31m9qyZPWNmraFsoZltMbPd4XZBKDczu93M2sxsu5ldWPQ6G0L93Wa2YWq6pOsBiIhMxPHsAfyGu1/g7mvD9k3AVndfDWwN2wBXAKvDz0bgDogCA7gFuBi4CLilEBpTwUxnAouIVPJGhoCuAu4O9+8Gri4q/6pHHgPmm9ky4HJgi7t3ufsRYAuw/g28f0WGhoBERCqZaAA48JCZbTOzjaFsqbsfAAi3S0L5cuDVoue2h7Jy5aOY2UYzazWz1s7Ozon3ZIyEmQ4Ci4hUkJpgvXe5+34zWwJsMbMXKtQtdR6uVygfXeB+J3AnwNq1a0/4E9xM00BFRCqZ0B6Au+8Ptx3A94jG8A+GoR3CbUeo3g6sLHr6CmB/hfIpYZiGgEREKqgaAGY2y8zmFO4D64DngM1AYSbPBuC+cH8zcH2YDXQJ0BOGiB4E1pnZgnDwd10omxLRQWAlgIhIORMZAloKfC9MrUwB33D3H5nZk8C9ZnYD8Apwbaj/AHAl0AYMAB8DcPcuM7sVeDLU+7S7d01aT8Yw00FgEZFKqgaAu+8Fzi9Rfhi4rES5AzeWea1NwKbjb+bxi4aAlAAiIuXE8kxgiBaE0+e/iEh5sQ0AM9MsIBGRCuIbAOggsIhIJbENADQEJCJSUWwDIKHrQoqIVBTbAIjOBNYugIhIOfENADQEJCJSSWwDQIvBiYhUFtsA0GJwIiKVxTYA0GJwIiIVxTYAoklASgARkXJiGwAJg3x+plshInLyim0AGDoILCJSSXwDQGcCi4hUFNsAiKaBiohIObENANCZwCIilcQ2ACxaDlRERMqIbQBoCEhEpLLYBoAWgxMRqSy+AYBmAYmIVBLfANAQkIhIRRMOADNLmtnTZnZ/2D7TzB43s91m9i0zqw/lDWG7LTy+qug1bg7lu8zs8snuzOj2gmsXQESkrOPZA/gEsLNo+6+AL7j7auAIcEMovwE44u5nAV8I9TCzNcB1wLnAeuDvzCz5xppfnoaAREQqm1AAmNkK4DeBL4dtAy4Fvh2q3A1cHe5fFbYJj18W6l8F3OPuaXd/CWgDLpqMTpRps5aCEBGpYKJ7AF8E/hgoLK+2COh292zYbgeWh/vLgVcBwuM9of5IeYnnTLqEloIQEamoagCY2fuBDnffVlxcoqpXeazSc4rfb6OZtZpZa2dnZ7XmlWWYpoGKiFQwkT2AdwEfMLN9wD1EQz9fBOabWSrUWQHsD/fbgZUA4fF5QFdxeYnnjHD3O919rbuvbWlpOe4OFWgxOBGRyqoGgLvf7O4r3H0V0UHch939I8AjwDWh2gbgvnB/c9gmPP6wR9NxNgPXhVlCZwKrgScmrSdjaBqoiEhlqepVyvoT4B4z+wvgaeCuUH4X8DUzayP65n8dgLs/b2b3AjuALHCju+fewPtXFM0CUgSIiJRzXAHg7o8Cj4b7eykxi8fdh4Bryzz/NuC2423kidAQkIhIZTE+E1iLgYqIVBLbAEiYaQhIRKSC2AaAAXl9/ouIlBXbAECzgEREKoptACS0GJyISEWxDQAtBiciUll8A0CLwYmIVBTfAEB7ACIilcQ2AKJpoDPdChGRk1dsAwBdFF5EpKLYBoChM4FFRCqJbQAktBaEiEhFsQ0A0xCQiEhFsQ4AffyLiJQX2wDQYnAiIpXFNgBAi8GJiFQS2wDQJSFFRCqLbwCATgUWEakgtgGQ0EFgEZGKYhsAZqZpoCIiFcQ3ANAIkIhIJfENAC0GJyJSUdUAMLNGM3vCzH5pZs+b2adC+Zlm9riZ7Tazb5lZfShvCNtt4fFVRa91cyjfZWaXT1WnovfSmcAiIpVMZA8gDVzq7ucDFwDrzewS4K+AL7j7auAIcEOofwNwxN3PAr4Q6mFma4DrgHOB9cDfmVlyMjtTzKbqhUVEYqJqAHikP2zWhR8HLgW+HcrvBq4O968K24THLzMzC+X3uHva3V8C2oCLJqUXJeh6ACIilU3oGICZJc3sGaAD2ALsAbrdPRuqtAPLw/3lwKsA4fEeYFFxeYnnFL/XRjNrNbPWzs7O4+/RyOtoCEhEpJIJBYC759z9AmAF0bf2c0pVC7elRl+8QvnY97rT3de6+9qWlpaJNK8kLQYnIlLZcc0Ccvdu4FHgEmC+maXCQyuA/eF+O7ASIDw+D+gqLi/xnElnaDE4EZFKJjILqMXM5of7TcB7gZ3AI8A1odoG4L5wf3PYJjz+sEefxJuB68IsoTOB1cATk9WR8e3WHoCISCWp6lVYBtwdZuwkgHvd/X4z2wHcY2Z/ATwN3BXq3wV8zczaiL75Xwfg7s+b2b3ADiAL3OjuucntzjE6D0BEpLKqAeDu24F3lCjfS4lZPO4+BFxb5rVuA247/mYev+hMYCWAiEg5sT0TWIvBiYhUFtsA0GJwIiKVxTcA0GJwIiKVxDYAMAWAiEglsQ2AhGk1IBGRSmIbAIaWghARqSS+AaAhIBGRimIbAAkzHCeXd/J5JYGIyFixDYBoNVC44FMP8Wufe2SmmyMictKZyFIQp6SEGfm805fO0pfOVn+CiEiNie0eQDJh5HQQQESkrNgGQMKMnMb+RUTKim0ApBIKABGRSmIbAEkFgIhIRbENgERCi8GJiFQS2wDQEJCISGWxDYCEGfr8FxEpL7YBkExoMTgRkUoUACIiNUoBICJSo+IbALoegIhIRVUDwMxWmtkjZrbTzJ43s0+E8oVmtsXMdofbBaHczOx2M2szs+1mdmHRa20I9Xeb2Yap61Y0DVRERMqbyB5AFvhDdz8HuAS40czWADcBW919NbA1bANcAawOPxuBOyAKDOAW4GLgIuCWQmhMhdSYAPjdr22bqrcSETklVQ0Adz/g7k+F+33ATmA5cBVwd6h2N3B1uH8V8FWPPAbMN7NlwOXAFnfvcvcjwBZg/aT2psjYPYAfPf/6VL2ViMgp6biOAZjZKuAdwOPAUnc/AFFIAEtCteXAq0VPaw9l5cqnhI4BiIhUNuEAMLPZwHeAP3D33kpVS5R5hfKx77PRzFrNrLWzs3OizRsnGdvD2yIik2NCH5NmVkf04f91d/9uKD4YhnYItx2hvB1YWfT0FcD+CuWjuPud7r7W3de2tLQcT19GSSaUACIilUxkFpABdwE73f2vix7aDBRm8mwA7isqvz7MBroE6AlDRA8C68xsQTj4uy6UTYlSewC6NrCIyDETuSTku4CPAs+a2TOh7H8AnwXuNbMbgFeAa8NjDwBXAm3AAPAxAHfvMrNbgSdDvU+7e9ek9KKERIljANm8U6/poSIiwAQCwN1/Sunxe4DLStR34MYyr7UJ2HQ8DTxRqRJDQFoeWkTkmNgOlJcaAspqCEhEZERsA6DUEJCuDyAickxsA6DUYnAKABGRYxQAIiI1SgEgIlKj4hsApY4BaBaQiMiI2AZAqeWgczkFgIhIQWwDYOxy0ADZfH4GWiIicnKKbQCU2gPQiWAiIsfENgBKHQPQiWAiIsfENwA0C0hEpCIFgIhIjVIAiIjUqNgGgNYCEhGpLLYBUGoaaC7vbHu5i9t+sGMGWiQicnKJbQCUGwL64B2/4B9+8hKuKaEiUuNiGwAlzwQu+tDXlFARqXWxDYDSZwIXBYCWhRCRGhfbACh5ELjoQz+jZSFEpMbFNgBKHgNw7QGIiBTENwCqTAPN5LQHICK1Lb4BkFQAiIhUUjUAzGyTmXWY2XNFZQvNbIuZ7Q63C0K5mdntZtZmZtvN7MKi52wI9Xeb2Yap6c4x1fYANAQkIrVuInsAXwHWjym7Cdjq7quBrWEb4ApgdfjZCNwBUWAAtwAXAxcBtxRCY6okSvRsVADoILCI1LiqAeDuPwa6xhRfBdwd7t8NXF1U/lWPPAbMN7NlwOXAFnfvcvcjwBbGh8qkqn4MQHsAIlLbTvQYwFJ3PwAQbpeE8uXAq0X12kNZufJxzGyjmbWaWWtnZ+cJNq/6LCAdAxCRWjfZB4HHf+qCVygfX+h+p7uvdfe1LS0tJ96QKheE6U9nGRjOnvDri4ic6k40AA6GoR3CbUcobwdWFtVbAeyvUD6t8kUB8OF/eJw1n3xwupsgInLSONEA2AwUZvJsAO4rKr8+zAa6BOgJQ0QPAuvMbEE4+LsulE0rrf8jInJMqloFM/sm8B5gsZm1E83m+Sxwr5ndALwCXBuqPwBcCbQBA8DHANy9y8xuBZ4M9T7t7mMPLE+5nGb+iIiMqBoA7v6hMg9dVqKuAzeWeZ1NwKbjat0blEzYqJk/Ou4rInJMbM8EBljQXDdqW3sAIiLHxDoA5jWNDYAZaoiIyEko1gHwm29fNmq71B6ArgwmIrUq1gHwB+89m0++f83Idq7Eh73OCBaRWhXrAEgkjNPnN45sl5oGOqxxIRGpUbEOgLGGhnPjytKZHMPZPKtu+gFf/sneGWiViMjMiH0AFI/6/GzP4XGPp7N5+oYyANy+dfd0NUtEZMZVPQ/gVFc86NPW0T/u8eFsfuRcgVLrB4mIxFXN7AHMH3NOQEE6m+doWBSu+PPf3fn2tnaGMuOHjURE4iD2AXDWktkAXHPhipKPp7M5jqZDABSV/6ztMH/0T7/ksz98gVzeR51RLCISB7EfAnrLaXN46s/fRyppfPmnL417fDibZyAcHC4eAupPR8cFvvLzfXzl5/tYPLue1j973/Q0WkRkGsQ+AAAWzqove8JXOpsvuQcwdutQ//DUNE5EZIbEfgiowMxYOKt+XHk6m6M/Pf4YQKnr1XT0DXHjN54amTUkInIqq5kAAEoGQPEQUPG3/oES5wx88V9284PtB/jnZ6b9WjYiIpOupgLgvOXzxpX913ueKbkHcLREAGSy0VnDCYPdB/tYddMP+NaTr3D9pid0jWEROeXUVACsO3fpuLLhbJ5dr/cBkC36EB9Ij79ecN9QVJYw4/u/jPYC/uQ7z/LjFzt5pWtgKposIjJlaioALj/3ND53zXn898vfMqp8e3s3MHrYp9QeQPdgdCB4cDg37gjBQDqqP5TJ8d++9QyvdQ9OYstFRCZfTcwCKjAz/v3a6Nr0Hzj/dL7++Cv833/dw77D0bf3dDgrOJmwknsA3QPRwd+ewQz5MbOKjgxE4fDwCx189+nXGM7l+ZsPXziV3REReUNqag+g2MqFzdx0xVvHnSH8zKvduHvJPYDCt/reoQzZXOkAGA7HCcYGRCnfevIVPv39HSOL0O07dHTcdFV352uPvUxH3xAQDVPpGgYiMhlqNgAKrnhbdNGY954THR/44B0/5/pNT/DNJ14ZV7dwDKBnMDPygV9w5Gi0fag/DUxsXaE/+c6zbPrZS/zFD3bybHsP7/nfj/LVX7w8qs4rXQP8+T8/x8e/8TRDmRxn/ekP+dtH2hjK5Djcn2bH/t7j7LGISKSmhoBK+dQHzuXXVi9mzbK5/MvOgwD8ZPehis955fAAbZ2jF5brCsNDB3qib+qFpacP9Axy2tzGcYEwdo2hn7R1AvCLPYfZ8G9XjZQX9jpe7Rpg3+GjAPzdo3t4bG8XP2071s5v/qdLeOevLKrY7sP9aX7v60/xuWvO402LZo167IfPHuDXz25hVkOKPZ39nLGwmbpk9P2gbyhDwoz6VGKkTEROfdP+f7OZrTezXWbWZmY3Tff7j1WfSnDl25fxpkXNI2Xrzz1t5P5tv/02PnzxGbz3nCWsXNgEQOvLR0aOBxTcvnU3D79wkBcPRjOKtr7QwaO7OnjnZx7mP39t28hKpOlsjq07D/LSoaOjnv/TEDpjdxxeDbOLcu6jVjMt/vAH+H+Pjd5zKOX7v9zP4y918aWH20aVb2/v5r98/SluvX8Hr/cMcdnn/5XPPPDCyOPnf+ohzr3lQc7+sx+WfN22jn5+60s/5WDvUNn3PprOcuM3nuKjdz3Olh0Hq7b1eOzp7OfxveOX+p5Kezv7SWe1UKCc2qZ1D8DMksDfAu8D2oEnzWyzu++YznaUYmZ87oPnMb+5jnXnnsbv3N3KqkXNfOTiN42q9/FvPj0yBXSs//iV1lHb/+EfnwTgoR0HeWjHQd7zlhZ+svtQyYXlfh6uVfDzPYd5+IWDtB8ZZM2yufz9j6PjAwd70zz5UhdQ+spmjjOUydFYlzxW5s5gJkdzfQp3H9k7SWej4wjPvNrNmtPn8uMXo72P3R39bHv5SGjz63zyt9bQO5Sh8HbusL872qNJJI4l1Zce3s2zr/Xwnafa+b33nFXyd7Nlx0F+sP0AEO1h7fvsb5asdyIu+/y/AtB22xWkJmEPZU9nP8+91sNVFywf91g2l+fb29q56bvPcu2vruB/XXv+G34/kZli03lA0czeCfxPd788bN8M4O6fKVV/7dq13traWuqhGdM7lCGdybPt5S6+/JOXaH35CLde/Taea+/hsZcOMzCc43ff/Svcen+UaVe+/TQ6etOkksb+7iHevmLeyAchwNzGFL1D42ccnYiEwWXnLKU+leDxvYdZPLuBlw4d5a3L5rK/e5DOvvRI3fnNdXQPZGhIJUhnS5/Eds2vrmB7ezcvHjy25zGnIUUqaVzy5kWcNq+RvqEsj+7qHDn2sf7c07jgjPls3XmQTM5599ktNNcn+cwPXxj12u8+u4W6ZILFs+tZsaCJ17oHSZjRWJdkT2c/7z67hYWz6nm9Z4h5TXUsnFVPNu90HR1mYDhLJufMbUzRPZDh81teBOD95y3jvBXzePnwAGtOn0t9CINs3mmsS7BsXhNL5zayY38vqaRx5OgwS+c1Mqs+xb5DR2nvHmTlgiY+9f0d9Kez/NG6s1kyt5HT5zVRlzQWz2nge0+9xt88cmwP6i9/++2sXNjEgZ4hWmY3MJzL0zOQ4fT5TQxlcmTzeRbOaqCzL00yYZjBnMYU29t7WLVoFvOb68jmnEw+z9zGFAtnNbBodj3pTJ7m+iTD2TwdfWn60xnMjJbZDbR19tNcl2R+c/S7OzIwzHA2T1N9kmwumsXWMqeBXa/3cfr8Jprrk6SzeTK5PMPZPAtn1ZNKGEPZPNlcnlQywaz6JMPh8cP9w8xrqmN+cx29g1nSuRwtsxuiVXHdyeejPdJcLtp2d+Y315PLO/Wp6Heey/vIyZGFvVrDiu5D3qEuafSnswwO51gy99jlWwt6hzI0ppIjrzuczZPN52mqS07K9Tv601kO9aV506Lm43q9dDZHQyr6snXk6DCvdQ/ythInms4UM9vm7mur1pvmALgGWO/uvxO2Pwpc7O6/X6r+yRgAxdyd4Vx+5A+hUGZmDGVyPLqrg3VrThv1bRmge2CYnsEMKxY0k0wY92/fz/kr5tNcn+Rnew5Hxw8sGhZ611mLaJnTQGMqSX86y5tbZvPsa9283pOmsy/NpW9dwq6DfXztF/v4tdUt/PC51xnO5kgkjP6hLHl38g4Xn7mQ9iODNNUnWTq3gcP9w+w62Me/edNCXuse5FB/eiQIUgkjm3dOn9dI71CWgeEsZy2ZzYsH+3nz4lksX9DEzgO99A5mWTirntPmRf/jDmfzdA8Ms79niAXNdSyYVc/ezmNDXQmDMxY201gX9aW5PskrXQMMhQ+7pBl9JabfHq9C+6fSnIbUpLR1JiQTNm4vdHZDauSM+IIT+T3Oa6pjKJMr+6VirLqkkcmNfw+z6ITLXN5pSCVIWBQehXN15jSkyOTz1CUSDIWhOMMI/2F2LHBs5DUtuj9Sx0a+TMxvriOXdxrrotDNe3Q/k8uTzzt1yQSJ8HvLu9M9kGFuY4r6VJLewQzDuTyLZx8LwYRFv7tC6Loz0haz0e0ayuaZ21hH3p1UIjrWNpTJcelbl/C5a05sD/NkDYBrgcvHBMBF7v7xojobgY0AZ5xxxq++/HL1sW0ZrRBChW933QPDzG8evw5SsWwuT+9Qls6+NGcvnU0u7yPDKYXX6x3K0FyXrDjMkss729u7OXvpHGY1pMjkotVW5zTWkUyM/4bV2ZembyjDmYtnYWZhbaYsh/qHOdAzyKpFszh8dJhUwkgljQXN9cxqiIa09nYepT6V4OylczjYO0Qu77jDigVNHOgdIh8+vJKJ6Fvm/u5B2o8MsnxBE/Oa6mhMJRnM5OgbytAyp4HVS+awv3uQjr40y+Y1RntIdYmR1z7cP0zLnAYuOnMhjXVJhjI5OvvSvHTo6EibEgljbmOKjt4oUFvmNPB6zxBL5jYwMJyjoy/N3MYUbz1tLh19QxwZyJBKRHs+nX1pDvYOkcnlaUgl6B3K0lSXZMncBuaED4j93YPMbaxjVkOS3sEs+3sGWTSrnoZUkoHhHKmkkcnlw3s2ks7kyOScuqTRkEqQTCRoPzJAfSox8kEF8NqRQRbPbqChLsHi2Q30Dmbo7E8zuyFFKmEMDOdIJoxkwkiYkUoYiYSRDP+kXQMZjOjLTWN9kqa65LgJA4XPmsJHjgO9gxlmN6ZoCP8WxRUyeY9OuvToQzWbdxY015N351B/mqa6JJmc01SfHHma44T/cPdR71V4fKTMo7/x0+Y2svdQPw2p6N/UzEhYtIdSn7To/6X8sXOEAGY31DE4nCWTj/aE0tlo+LUumSCdzeEOqWSCuqRRn0xgVnj/0e1wj8Ll6HB2JJjTmTyN9UnesXI+14bzlo7XyRoAp/wQkIjIyW6iATDds4CeBFab2ZlmVg9cB2ye5jaIiAjTPAvI3bNm9vvAg0AS2OTuz09nG0REJDLtJ4K5+wPAA9P9viIiMppO6xQRqVEKABGRGqUAEBGpUQoAEZEapQAQEalR03oi2PEys07gjZwKvBiovLZzvNRaf0F9rhXq8/F5k7u3VKt0UgfAG2VmrRM5Gy4uaq2/oD7XCvV5amgISESkRikARERqVNwD4M6ZbsA0q7X+gvpcK9TnKRDrYwAiIlJe3PcARESkjFgGwMl24fnJYmabzKzDzJ4rKltoZlvMbHe4XRDKzcxuD7+D7WZ24cy1/MSZ2Uoze8TMdprZ82b2iVAe236bWaOZPWFmvwx9/lQoP9PMHg99/lZYUh0zawjbbeHxVTPZ/hNlZkkze9rM7g/bce/vPjN71syeMbPWUDatf9exC4CiC89fAawBPmRma2a2VZPmK8D6MWU3AVvdfTWwNWxD1P/V4WcjcMc0tXGyZYE/dPdzgEuAG8O/Z5z7nQYudffzgQuA9WZ2CfBXwBdCn48AN4T6NwBH3P0s4Auh3qnoE8DOou249xfgN9z9gqLpntP7d+3hos5x+QHeCTxYtH0zcPNMt2sS+7cKeK5oexewLNxfBuwK9/8e+FCpeqfyD3Af8L5a6TfQDDwFXEx0UlAqlI/8nRNdX+Od4X4q1LOZbvtx9nMF0QfepcD9RJfMjW1/Q9v3AYvHlE3r33Xs9gCA5cCrRdvtoSyulrr7AYBwuySUx+73EHb13wE8Tsz7HYZDngE6gC3AHqDb3QtXbi/u10ifw+M9wKLpbfEb9kXgj4HC1eQXEe/+QnSJ4IfMbFu4FjpM89/1tF8QZhqMv/J49Isis9o6AAAB00lEQVSuNbH6PZjZbOA7wB+4e69Zqe5FVUuUnXL9dvcccIGZzQe+B5xTqlq4PaX7bGbvBzrcfZuZvadQXKJqLPpb5F3uvt/MlgBbzOyFCnWnpM9x3ANoB1YWba8A9s9QW6bDQTNbBhBuO0J5bH4PZlZH9OH/dXf/biiOfb8B3L0beJTo+Md8Myt8aSvu10ifw+PzgK7pbekb8i7gA2a2D7iHaBjoi8S3vwC4+/5w20EU8hcxzX/XcQyAWrvw/GZgQ7i/gWiMvFB+fZg9cAnQU9i1PJVY9FX/LmCnu/910UOx7beZtYRv/phZE/BeooOjjwDXhGpj+1z4XVwDPOxhoPhU4O43u/sKd19F9P/rw+7+EWLaXwAzm2Vmcwr3gXXAc0z33/VMHwiZooMrVwIvEo2b/ulMt2cS+/VN4ACQIfpGcAPR2OdWYHe4XRjqGtFsqD3As8DamW7/Cfb53xHt6m4Hngk/V8a538B5wNOhz88BnwzlbwaeANqAfwIaQnlj2G4Lj795pvvwBvr+HuD+uPc39O2X4ef5wufUdP9d60xgEZEaFcchIBERmQAFgIhIjVIAiIjUKAWAiEiNUgCIiNQoBYCISI1SAIiI1CgFgIhIjfr/A0xzBGd9t4oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(deltas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal degradation for repair= 8.301673852236808\n",
      "cost for repair = 421.86127116537693\n",
      "Time for repair = 10.853747714808044\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimal_value =[]\n",
    "current_state = 0 #it is new\n",
    "degradation = 0\n",
    "optimal_cost = []\n",
    "expected_optimal_cost=[]\n",
    "num=[]\n",
    "numm =[]\n",
    "\n",
    "        \n",
    "for j in range(2000+1):\n",
    "    #Choose A from S\n",
    "    action = np.argmax(Q[current_state])\n",
    "    if action == 1:\n",
    "        optimal_value.append(degradation) \n",
    "        num.append(j)\n",
    "    \n",
    "    numm =[3*num[i] - 3*num[i-1] for i in range(1, len(num))]\n",
    "    #print(num , numm)\n",
    "    # Take action\n",
    "    current_state, reward ,degradation= Envirenment(degradation,action)\n",
    "    optimal_cost.append(-reward)\n",
    "    #print(optimal_cost)\n",
    "    if any(np.array(optimal_cost) > 50):\n",
    "        expected_optimal_cost.append(np.mean(optimal_cost))\n",
    "    if action ==1:\n",
    "        optimal_cost = []\n",
    "    #print (reward ,degradation , action)\n",
    "    \n",
    "#print(optimal_value)\n",
    "#print(\".................\")\n",
    "#print(expected_optimal_cost)\n",
    "#print(\".................\")\n",
    "print(\"optimal degradation for repair=\",np.mean(optimal_value))\n",
    "#print(\".................\")\n",
    "print(\"cost for repair =\",np.mean(expected_optimal_cost))\n",
    "print(\"Time for repair =\",np.mean(numm))\n",
    "#print(\"Time for repair =\",numm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m2u2HZ4T64e"
      },
      "source": [
        "# MCRL for article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "X20KoE6dT64j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "7l8UBe-FT64l"
      },
      "outputs": [],
      "source": [
        "z = 10 #Degradation threshold\n",
        "\n",
        "def state(amount):\n",
        "    new_state = []    \n",
        "    if (amount >= 0 and amount <2):\n",
        "        new_state = 0 # healthy1\n",
        "    \n",
        "    if (amount >= 2 and amount <7):\n",
        "        new_state = 1 # healthy2\n",
        "        \n",
        "    if (amount >= 7 and amount < z ):\n",
        "        new_state = 2 #healthy3 \n",
        "        \n",
        "    if (amount >= z):\n",
        "        new_state = 3 # fail\n",
        "    \n",
        "    return new_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "fd6WG21PT64n"
      },
      "outputs": [],
      "source": [
        "def Rewardfun(degradation):\n",
        "    Reward=np.zeros((4,)+(3,))\n",
        "    Reward[: , 0] = -50\n",
        "    Reward[3,0] = -1050\n",
        "    Reward[: , 1] = -500*(degradation/z)-50\n",
        "    Reward[3,1] = -1150\n",
        "    Reward[: , 2] = -550\n",
        "    Reward[3,2] = -1550\n",
        "       \n",
        "    return Reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "UW0WsiK2T64q"
      },
      "outputs": [],
      "source": [
        "def possible_action(state):\n",
        "    if state == 0 :\n",
        "        return [0,1]\n",
        "    if state == 1 :\n",
        "        return [0,1,2]\n",
        "    if state == 2:\n",
        "        return [0,1,2]\n",
        "    if state == 3:\n",
        "        return [2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJvHiZxlT64r",
        "outputId": "1e982476-9666-4b4b-da7f-237dc483e54b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "possible_action(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfpaC0e0T64t",
        "outputId": "51e270ef-c58f-4666-c8db-226b6f0a0cc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "len(possible_action(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "80dUqLrjT64v"
      },
      "outputs": [],
      "source": [
        "def Envirenment(degradation , action,a):\n",
        "   \n",
        "    n2 = np.random.poisson((1-0.001)*4, 1) # number of effective shock\n",
        "    w2 = np.random.gamma(0.6, 1.2, n2) # magnitude of effective shock\n",
        "    magnitude = sum(w2)\n",
        "    next_state = 0\n",
        "    reward = 0\n",
        "    \n",
        "    if action == 0 :#do nothing\n",
        "        \n",
        "            degradation += (magnitude + 3)/a\n",
        "            next_state=state(degradation)\n",
        "            Reward=Rewardfun(degradation)\n",
        "            reward=Reward[next_state,action]\n",
        "        \n",
        "    if action == 1 : #repair\n",
        "        \n",
        "           # decay = degradation*np.random.beta(0.5, 1, 1)\n",
        "            #decay = degradation/z\n",
        "            #degradation -= decay*degradation\n",
        "            degradation = np.max((0.05, degradation))\n",
        "            decay =(np.random.gamma(degradation*degradation/2,2/(degradation),1)/z)[0]\n",
        "            degradation -= np.max((0, decay*degradation))\n",
        "            degradation = np.max((0.05, degradation))\n",
        "            degradation += (magnitude + 2.95)/a\n",
        "            next_state=state(degradation)\n",
        "            Reward=Rewardfun(degradation)\n",
        "            reward=Reward[next_state,action]\n",
        "                    \n",
        "    if action == 2 : # replace\n",
        "        \n",
        "            degradation = (magnitude + 2.85)/a\n",
        "            next_state=state(degradation)\n",
        "            Reward=Rewardfun(degradation)\n",
        "            reward=Reward[next_state,action]\n",
        "       \n",
        "    \n",
        "    return next_state , reward , degradation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWjJ0bIuT64w",
        "outputId": "9762e960-1446-4109-b8d3-60f7f7c1288a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, -215.9686245540393, 3.319372491080786)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "Envirenment(6.929383290900782 , 1,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rlFTSUbT64x"
      },
      "source": [
        "# pi function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Pw45yW2fT64y"
      },
      "outputs": [],
      "source": [
        "def policy_using_pi(state, pi):\n",
        "    return np.random.choice(possible_action(state), p=[pi[(state,a)] for a in possible_action(state)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "-Rq3ZE6QT640"
      },
      "outputs": [],
      "source": [
        "#np.zeros((4,3))\n",
        "#np.array([[0.5,0.5,0],[0.33,0.34,0.33],[0.33,0.33,0.34],[0,0,1]])\n",
        "pi = np.array([[0.7,0.3,0],[0.34,0.33,0.33],[0.33,0.34,0.33],[0,0,1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0PaYGDhT640",
        "outputId": "b5fef36f-c3cc-4584-c575-c824c84fdde0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "policy_using_pi(0, pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7OLAb6NWT641"
      },
      "outputs": [],
      "source": [
        "def choose_action(current_state, pi):\n",
        "    return policy_using_pi(current_state, pi)  #epsilon_soft       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F0_fH4fT643"
      },
      "source": [
        "# Episode Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "joTYizEtT643"
      },
      "outputs": [],
      "source": [
        "GAMMA =  0.5\n",
        "def play_episode(pi):\n",
        "    #S0,A0,R1,S1,A1,R2,S2,A2,R3 ,...\n",
        "    #s = 0 #it is new\n",
        "    #d = 0 #it is new\n",
        "    \n",
        "    d = np.random.uniform(0 , 10) #random\n",
        "    s = state(d)\n",
        "    a= choose_action(s, pi)\n",
        "    \n",
        "    #r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
        "    states_actions_rewards = [((s, a, 0))]\n",
        "    \n",
        "    for j in range(100 +1):\n",
        "    \n",
        "        s , r ,d  = Envirenment(d,a,8)\n",
        "        if (j == 100):\n",
        "            states_actions_rewards.append((s, None, r))\n",
        "        else:\n",
        "            a= choose_action(s, pi)\n",
        "            states_actions_rewards.append((s,a, r))\n",
        "            \n",
        "    \n",
        "     # calculate the returns by working backwards from the terminal state\n",
        "    G = 0\n",
        "    states_actions_returns = []\n",
        "    first = True\n",
        "    for s, a, r in reversed(states_actions_rewards):\n",
        "        \n",
        "       # the value of the terminal state is 0 by definition\n",
        "       # we should ignore the first state we encounter\n",
        "        # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
        "        if first:\n",
        "            first = False\n",
        "        else:\n",
        "            states_actions_returns.append((s, a, G))\n",
        "        G = r + GAMMA*G\n",
        "    \n",
        "    return states_actions_returns \n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "JgEeiKeGT645"
      },
      "source": [
        "#GAMMA =  0.9\n",
        "\n",
        "def play_episode_F(pi):\n",
        "    #S0,A0,R1,S1,A1,R2,S2,A2,R3 ,...\n",
        "    \n",
        "    d = np.random.uniform(0 , 10) #random\n",
        "    s = state(d)\n",
        "    a= choose_action(s, pi)\n",
        "    \n",
        "    #r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
        "    states_actions_rewards = [((s, a, 0))]\n",
        "    \n",
        "    while not s == 3:\n",
        "    \n",
        "        s , r ,d  = Envirenment(d,a)\n",
        "        if (s == 3):\n",
        "            states_actions_rewards.append((s, None, r))\n",
        "        else:\n",
        "            a= choose_action(s, pi)\n",
        "            states_actions_rewards.append((s,a, r))\n",
        "            \n",
        "    \n",
        "     # calculate the returns by working backwards from the terminal state\n",
        "    G = 0\n",
        "    states_actions_returns = []\n",
        "    first = True\n",
        "    for s, a, r in reversed(states_actions_rewards):\n",
        "        \n",
        "       # the value of the terminal state is 0 by definition\n",
        "       # we should ignore the first state we encounter\n",
        "        # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
        "        if first:\n",
        "            first = False\n",
        "        else:\n",
        "            states_actions_returns.append((s, a, G))\n",
        "        G = r + GAMMA*G\n",
        "    \n",
        "    return states_actions_returns \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "HSAtixOXT647"
      },
      "outputs": [],
      "source": [
        "#pi = np.array([[0.99,0.01,0],[0.34,0.33,0.33],[0.33,0.34,0.33],[0,0,1]])\n",
        "#play_episode_F(pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "aER7gcsXT648"
      },
      "outputs": [],
      "source": [
        "#print(np.full((4,3), 0.5)) \n",
        "#print(np.zeros((4, ) + (3,)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2UAAWnulT648"
      },
      "outputs": [],
      "source": [
        "def epsilon_rate(t):\n",
        "    \n",
        "    \"\"\"Gets value for learning rate. It declines as we advance in episodes.\"\"\"\n",
        "    # Learning rate also declines as we add more episodes\n",
        "    return max(minepsilon, min(1., 1. - math.log10((t + 1) / decay)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "bYPWKrB6T649"
      },
      "outputs": [],
      "source": [
        "minepsilon = 0.00001\n",
        "decay = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_Z1BwjCT649",
        "outputId": "14382e33-9d46-4072-ca04-0d474b678f56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.573620290359435"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "np.random.uniform(0 , 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f_yhZ-gT64-"
      },
      "source": [
        "# Run all episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "O00sDMR6T64_"
      },
      "outputs": [],
      "source": [
        "def counter_state_action(counter_matrix, state_action):\n",
        "    counter_matrix[state_action] += 1\n",
        "    return counter_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ioDF0T7WT64_"
      },
      "outputs": [],
      "source": [
        "counter_matrix = np.zeros((4,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-AcNKWAT65A",
        "outputId": "23db7910-ac98-4312-9e40-8120161fdd08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "counter_state_action(counter_matrix, (1,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Z3bGmxkQT65B"
      },
      "outputs": [],
      "source": [
        "epsilon = 1\n",
        "learning_rate = 1\n",
        "pi = np.array([[0.99,0.01,0],[0.34,0.33,0.33],[0.33,0.34,0.33],[0,0,1]])\n",
        "Q = np.zeros((4, ) + (3,))\n",
        "old_Q = 0 \n",
        "\n",
        "counter_matrix = np.zeros((4,3))\n",
        "\n",
        "Q[3,0]= -100000000\n",
        "Q[3,1]= -100000000\n",
        "Q[0,2]= -100000000\n",
        "\n",
        "returns =np.zeros((4,) + (3,))\n",
        "N = np.zeros((4 ,) + (3,))\n",
        "\n",
        "deltas = []\n",
        "\n",
        "\n",
        "for epi in range(600 +1):# Looping through episodes \n",
        "    \n",
        "    # generate an episode using pi\n",
        "    biggest_change = 0\n",
        "    states_actions_returns = play_episode(pi)\n",
        "    \n",
        "    seen_state_action_pairs = set()\n",
        "    for s, a, G in states_actions_returns:\n",
        "        # check if we have already seen s\n",
        "        # called \"first-visit\" MC policy evaluation\n",
        "    \n",
        "        state_action = (s,a)\n",
        "        \n",
        "        if state_action not in seen_state_action_pairs:\n",
        "        #if 1 == 1:   \n",
        "            returns[s][a] += G\n",
        "            N[s][a] +=1\n",
        "            old_Q = Q[s][a]    \n",
        "            Q[s][a] = returns[s][a] /N[s][a] # Average reward across episodes\n",
        "            \n",
        "            biggest_change = max(biggest_change, np.abs(old_Q - Q[s][a]))\n",
        "            seen_state_action_pairs.add(state_action)\n",
        "            \n",
        "            counter_state_action(counter_matrix, state_action)\n",
        "              \n",
        "            #for each s in the episode         \n",
        "            A_star = np.argmax(Q[s])# Finding the action with maximum value \n",
        "            \n",
        "            for a in possible_action(s): # Update action probability \n",
        "                if a == A_star:\n",
        "                    pi[(s,a)] = 1 - epsilon + (epsilon / len(possible_action(s)))\n",
        "                else:\n",
        "                    pi[(s,a)] = (epsilon / len(possible_action(s)))\n",
        "                     \n",
        "    \n",
        "    learning_rate *= 0.99\n",
        "    epsilon *= 0.99  \n",
        "    #epsilon = epsilon_rate(epi)\n",
        "    #eps = epsilon - 0.0005\n",
        "    #epsilon = max (0, eps)\n",
        "    deltas.append(biggest_change)\n",
        "                  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PDp04b3T65C",
        "outputId": "51ff78e2-ae95-4505-a117-e2383f09c13b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[599., 231.,   0.],\n",
              "       [601., 382., 376.],\n",
              "       [125., 564., 125.],\n",
              "       [  0.,   0.,  12.]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "counter_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fklyV5DiT65D",
        "outputId": "bce29b73-4767-41fe-8918-30a4bc6584cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0023809591983979563\n",
            "[[-1.04322749e+02 -2.15949178e+02 -1.00000000e+08]\n",
            " [-1.11508233e+02 -2.83165011e+02 -6.01037235e+02]\n",
            " [-2.62851827e+02 -2.43246654e+02 -6.20147939e+02]\n",
            " [-1.00000000e+08 -1.00000000e+08 -6.11820093e+02]]\n",
            "[[9.98797495e-01 1.20250465e-03 0.00000000e+00]\n",
            " [9.98396660e-01 8.01669764e-04 8.01669764e-04]\n",
            " [8.01669764e-04 9.98396660e-01 8.01669764e-04]\n",
            " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(epsilon)\n",
        "print (Q)\n",
        "print(pi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "V804mKYiT65E",
        "outputId": "12544543-c88a-4af9-d6f3-3949d219c49a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD6CAYAAABamQdMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgaklEQVR4nO3dfXRcd53f8fd3ZvTk5ychjO3ECTgJKSWJ0UIClIV4wybZXZK2QEM5xCfHrdsew8JZthDKOV223e2GpSUkdMkhEMBpCRDCQ3wgDRgnaULZPCiO8+gYKw+OrdiWbEuy9TSjmfn2j/sbeSSPRiNZsnRnPq9zdObe3/3NzO/K8md+87u/e6+5OyIiUl0Ss90AERGZfgp3EZEqpHAXEalCCncRkSqkcBcRqUIKdxGRKjRhuJvZ+Wa2q+jnuJl9xsyWmdl2M9sbHpeG+mZmt5pZu5k9Y2brZ343RESkmE1mnruZJYEO4F3AFuCYu99kZjcCS93982Z2NfAp4OpQ7xZ3f1e5112xYoWvXbt2irsgIlKbnnzyySPu3lxqW2qSr7UBeMnd95nZNcD7Q/lW4CHg88A1wJ0efWo8amZLzGylux8c70XXrl1LW1vbJJsiIlLbzGzfeNsmO+Z+HfCDsNxSFNiHgJawvArYX/ScA6FsbKM2m1mbmbV1dXVNshkiIlJOxeFuZvXAh4Afj90WeumTuo6Bu9/u7q3u3trcXPJbhYiITNFkeu5XATvd/XBYP2xmKwHCY2co7wDWFD1vdSgTEZEzZDLh/jFODskAbAM2huWNwL1F5deHWTOXAr3lxttFRGT6VXRA1czmA1cA/66o+CbgbjPbBOwDPhrK7yOaKdMODAA3TFtrRUSkIhWFu7v3A8vHlB0lmj0ztq4TTZMUEZFZojNURUSqUFWEe89Ahl8+o2F9EZGCqgj3LXftZMtdO+noGZztpoiIzAlVEe4d3VGoZ7L5WW6JiMjcUBXhrrvAioiMVhXhLiIio1VFuNtsN0BEZI6pinDXsIyIyGhVEe4F6sGLiESqKtzVgxcRiVRVuIuISKSqwt2AI31pvvFQO5O5faCISLWpqnAH+OzdT/P39+9h1/6e2W6KiMisqbpw70tnAcjl1XMXkdpVdeEuIiJVGO4aaxcRqZJwL5XnpknvIlLDqiLcRURktKoI9+JeugZlRESqJNw1zC4iMlpVhHuBma4vIyICFYa7mS0xs3vM7EUz221ml5nZMjPbbmZ7w+PSUNfM7FYzazezZ8xs/czuwmjqxIuIVN5zvwW4390vAC4CdgM3AjvcfR2wI6wDXAWsCz+bgdumtcUVUx9eRGrXhOFuZouB9wF3ALh7xt17gGuAraHaVuDasHwNcKdHHgWWmNnKaW63iIiUUUnP/RygC/iumT1lZt82s/lAi7sfDHUOAS1heRWwv+j5B0LZKGa22czazKytq6tr6nsgIiKnqCTcU8B64DZ3vwTo5+QQDAAenRY6qeFud7/d3VvdvbW5uXkyTz31tYreWjNnREQqC/cDwAF3fyys30MU9ocLwy3hsTNs7wDWFD1/dSg7o3SGqojUsgnD3d0PAfvN7PxQtAF4AdgGbAxlG4F7w/I24Powa+ZSoLdo+GZGWDh4WtxrVw9eRGpZqsJ6nwK+b2b1wMvADUQfDHeb2SZgH/DRUPc+4GqgHRgIdWeUawKkiMgoFYW7u+8CWkts2lCirgNbTq9ZU1Mc8RqWEZFaVmnPfU761fOH+OnOA2SyeUCX+xURKYj15QdeOdLPr54/TC4/2y0REZlbYh3uhZGXQo990vMxRUSqVLzDPaR7IdCLR2U05C4itSzW4Z4I6Z4vMdauHryI1LJYh3vByWxXpIuIQMzD3axw8lIYc9ewjIgIEPdwD4/qr4uIjBbvcB+T7gp5EZFIvMM9PI6aLaMTmUREYh7uY8bcS20TEalFMQ/36DE/MiyjXruICMQ93Mesa0RGRCQS63AvdN3VYxcRGS3W4V7ouY8MyyjjRUSAmId7YszFZdSDFxGJxDrcTx5QLbpB9iy1RURkLol3uIfHUleF1I07RKSWxTvcC6MyuiqkiMgo8Q53CrNlTlKHXUSkwnA3s1fN7Fkz22VmbaFsmZltN7O94XFpKDczu9XM2s3sGTNbP2OtH+m5j34cuywiUmsm03P/gLtf7O6tYf1GYIe7rwN2hHWAq4B14WczcNt0NXassScx/bb9yMmLiWlgRkRq2OkMy1wDbA3LW4Fri8rv9MijwBIzW3ka7zOusdeP+fL9L3Kge3Am3kpEJFYqDXcHfm1mT5rZ5lDW4u4Hw/IhoCUsrwL2Fz33QCgbxcw2m1mbmbV1dXVNoemlb8jRn85GDVbHXURqWKrCeu919w4zewOw3cxeLN7o7m5mk4pTd78duB2gtbV1SlFc7sKPynYRqWUV9dzdvSM8dgI/A94JHC4Mt4THzlC9A1hT9PTVoWzalQ13pbuI1LAJw93M5pvZwsIy8EHgOWAbsDFU2wjcG5a3AdeHWTOXAr1FwzfTKlEi3ZXpIiKVDcu0AD8LBy9TwF3ufr+ZPQHcbWabgH3AR0P9+4CrgXZgALhh2ltdAZ2hKiK1bMJwd/eXgYtKlB8FNpQod2DLtLRuAuXutqRoF5FaFvMzVEVEpJR4h3updNe13UVEYh7uZfruura7iNSyeId7qWwfex1gEZEaFO9wL1WoUBcRiXm46wxVEZGSYh3u5ebL6ICqiNSyWId7uZ67iEgti3W4l7r8QIFmy4hILYt1uJfruGtYRkRqWbzDXQdURURKqrpw13CMiEjcw73EwMzJm2Ur5EWkdsU63MsNuivaRaSWxTrcy1w3TESkpsU73HVEVUSkpHiHe5kyHVgVkVoW73DXGaoiIiXFO9xL9N3zYZaMJsuISC2Ld7iXnOceHhXuIlLDKg53M0ua2VNm9ouwfo6ZPWZm7Wb2IzOrD+UNYb09bF87Q20vHe6Fee4z9aYiIjEwmZ77p4HdRetfBm5297cA3cCmUL4J6A7lN4d6M6LcbfZERGpZReFuZquBPwG+HdYNuBy4J1TZClwblq8J64TtG6zsnMWpKzsTUuMyIlLDKu25fw34HJAP68uBHnfPhvUDwKqwvArYDxC294b6o5jZZjNrM7O2rq6uKTW+7FUhp/SKIiLVYcJwN7M/BTrd/cnpfGN3v93dW929tbm5eUqvMUNfCEREYi9VQZ33AB8ys6uBRmARcAuwxMxSoXe+GugI9TuANcABM0sBi4Gj095yJhqWmYl3FBGJhwl77u7+BXdf7e5rgeuAB9z948CDwIdDtY3AvWF5W1gnbH/AZ2gAvHy/XekuIrXrdOa5fx74CzNrJxpTvyOU3wEsD+V/Adx4ek0cn3ruIiKlVTIsM8LdHwIeCssvA+8sUWcI+Mg0tK0CGnMXESml6s5QLVDHXURqWbzDvcw2DcuISC2LdbgnNBVSRKSkWId7+WEZdd1FpHbFO9zLDMxoWEZEalm8w10HVEVESop1uIuISGmxDnddFVJEpLR4h7tOYhIRKSne4a5sFxEpqWrDXaMyIlLL4h3u5aZCar6MiNSweIe7hmVEREqKdbgnNCwjIlJSrMO93KXDFO4iUstiHe46Q1VEpLR4h/tsN0BEZI6Kd7iX6brrDFURqWXxDvcy2xTtIlLL4h3uGpcRESkp3uFeru+urruI1LAJw93MGs3scTN72syeN7O/DuXnmNljZtZuZj8ys/pQ3hDW28P2tTPVeN2JSUSktEp67mngcne/CLgYuNLMLgW+DNzs7m8BuoFNof4moDuU3xzqnXE6nioitWzCcPdIX1itCz8OXA7cE8q3AteG5WvCOmH7Bis3reU0aMxdRKS0isbczSxpZruATmA78BLQ4+7ZUOUAsCosrwL2A4TtvcDyEq+52czazKytq6trSo0vOxVySq8oIlIdKgp3d8+5+8XAauCdwAWn+8bufru7t7p7a3Nz85ReQ9eWEREpbVKzZdy9B3gQuAxYYmapsGk10BGWO4A1AGH7YuDodDR2LN2JSUSktEpmyzSb2ZKw3ARcAewmCvkPh2obgXvD8rawTtj+gM/Q6aKaLSMiUlpq4iqsBLaaWZLow+Bud/+Fmb0A/NDM/gZ4Crgj1L8D+F9m1g4cA66bgXYDE5yhqmwXkRo2Ybi7+zPAJSXKXyYafx9bPgR8ZFpaNxGdwyQiUlL1nqEqIlLD4h3uGpcRESkp3uFeZpuiXURqWbzDXaeoioiUFO9wL7NNozIiUsviHe5lz1BVuotI7Yp5uOvaMiIipcQ83Ge7BSIic1O8w73MNo3KiEgti3e4a1hGRKSkeIf7bDdARGSOine4a7aMiEhJ8Q73Mn33v/nlboaGc2ewNSIic0e8w32CcZmdr3WfmYaIiMwxsQ53EREpLdbhrnnuIiKlxTvcNV9GRKSkWId7QtkuIlJSrMNdl/wVESkt3uE+2w0QEZmjJgx3M1tjZg+a2Qtm9ryZfTqULzOz7Wa2NzwuDeVmZreaWbuZPWNm62eq8eq4i4iUVknPPQt81t0vBC4FtpjZhcCNwA53XwfsCOsAVwHrws9m4LZpb3WgYRkRkdImDHd3P+juO8PyCWA3sAq4Btgaqm0Frg3L1wB3euRRYImZrZzuhouIyPgmNeZuZmuBS4DHgBZ3Pxg2HQJawvIqYH/R0w6EsrGvtdnM2sysraura7LtLnqdMhsdjvVnpvzaIiJxVXG4m9kC4CfAZ9z9ePE2j67SNakrdbn77e7e6u6tzc3Nk3nq6HaV2XbX46+x/r9u5/eHT0z59UVE4qiicDezOqJg/767/zQUHy4Mt4THzlDeAawpevrqUDYjyo27/7b9CADtnX0z9fYiInNSJbNlDLgD2O3uXy3atA3YGJY3AvcWlV8fZs1cCvQWDd9Mu3I992QI/mxel/8VkdqSqqDOe4BPAM+a2a5Q9p+Am4C7zWwTsA/4aNh2H3A10A4MADdMZ4PHKjfmnginsOYV7iJSYyYMd3f/LeN3kDeUqO/AltNsV8Wi68uUDu9Czz2ncBeRGhPrM1Rhgp572JbTXZlEpMZUdbgXDrZqWEZEak38w72CK8yo5y4itSb+4V72gGr0qJ67iNSa2Id7ssxF3Qu9ek2FFJFaE/twT5UL98IBVYW7iNSY2Id7MjH+LhRiP68xdxGpMbEP9/I998I89zPVGhGRuSH24V52zD1sUs9dRGpN7MM9lSx3QDWSzSncRaS2xD7cy/fcw7CMeu4iUmNiH+7lxtw9hLrmuYtIrYl9uJebLVOYAql57iJSa2If7uV67oVQz2q6jIjUmNiHe7kx98KB1GGFu4jUmNiHeyU992ENy4hIjYl9uJftueejHvtwVj13EaktsQ/3cvPccxqWEZEaFftwLzdbZrjQc9dJTCJSY2If7mXH3HOFqZAT99x/99IR7n/u4LS1S0RkNk0Y7mb2HTPrNLPnisqWmdl2M9sbHpeGcjOzW82s3cyeMbP1M9l4mGjMPQr3Si75+6+/9Rj//n/vnLZ2iYjMpkp67t8DrhxTdiOww93XATvCOsBVwLrwsxm4bXqaOb5yPfcCncQkIrVmwnB394eBY2OKrwG2huWtwLVF5Xd65FFgiZmtnKa2llSu516gm3WISK2Z6ph7i7sXBqgPAS1heRWwv6jegVA2YyrquU/igKrrImMiUgVO+4CqR2k46UQ0s81m1mZmbV1dXVN+/3KzZQom03MfHM5NuS0iInPFVMP9cGG4JTx2hvIOYE1RvdWh7BTufru7t7p7a3Nz8xSbAXVl5rkXVDJbpqAvnZ1yW0RE5oqphvs2YGNY3gjcW1R+fZg1cynQWzR8MyOme8y9P62eu4jEX2qiCmb2A+D9wAozOwD8FXATcLeZbQL2AR8N1e8DrgbagQHghhlo85j2TVxnMrNl+obUcxeR+Jsw3N39Y+Ns2lCirgNbTrdRk5EennjIZTI9dw3LiEg1iP0ZqkMVXBRsMteW6Ve4i0gViH24D2YmHiOfTM89rStIikgViH24p7MTh/tkxtzL9fIP9Q7x6MtHK34tEZHZEvtwn+6ee6ZMuF91y8Ncd/ujFb+WiMhsiX24D53Bnnv3wHDFryMiMptiH+7T3XOv5K5NukSBiMx1sQ/3xrrkhHWyFcyWKcyXr+TGHrr5h4jMdbEP929+4h188eq3lq1TSc89EdK93Jh7QSV1RERmU+zDffXSefzb951btk4lY+6FE10rmROvG26LyFwX+3CvRCU997yfejPtvYdPcGLo1IOo6rmLyFxXE+GezXvZg6D5vFPI/8J4eteJNFfc/DDvvumBU+pn1HMXkTmuJsIdyvfei4dtCsHdPZAB4ESJC4mp5y4ic13NhHu5cffi4C8MywyUmWKpnruIzHU1E+7le+4nw/pkuJ/ssefHPHc4l+f/PHuQzuND09xKEZHpUTPhXnnPPVouPjlqKJsbVad3cJj/8P2dXP+dx2egpSIip69mwr3cNWFGjbmXGJYZyOQYKrq36rH+aDz+xUMneL1ncLqbKiJy2mom3HcfPD7utlE99zCeXtxzH8zkOF40JfKzdz89svzumx7gxp88MzIb529/+QIP7ulERGQ21Uy4l5MteUD15Jj74HCOnqKLho0d4vnhE/s5PpQln3e+9cgr3PDdJ/iHB9v5XfsRXjnSP8OtFxE51YS32asmL3X18ebmBQDsOxqF7tnL54+69kwhuAeGR/fc+zPl79DUM5AZ9Tpf+dWekeUnvvhHNC9sOP0dmCVf3f579h3t55brLilbbziXpz+dZcm8+jPUMhEZT0313Df8j/87svyHX3mIP/zKQ0Dpee5DY8bceya43O+x/gyPvnys5LY/+Nvf8M+/8f842BvP8flbd+zl3l2vT1jvP/74aS7+L9tPmV000471Z9h7+MQZfU+Rua5qwv3rH7uEi9csAWDbJ9/DB85vLlnvlSP93PmPr46sv3joOJ+866mR9VLz3IeGcyMnNY3nSF+GLXftHHf7U6/18Pf37xl3+3j601lu+O7jPNfRy+fueZovbXue37xweFbm2k903Z2fhw+AI33pM9GcEX/29d9yxc0Pz/ilmG9/+CVu3bF3Rt9DZLrMyLCMmV0J3AIkgW+7+00z8T7F/uyiN3Hl297InkMneNuqxbzvvGYe3NPFv1y/mp/sPDBS7wP//aFRz7vya4+MWj98PM3f3bebvZ19I2UDmRwP/76r7Ps/c6Bnwja+8Pr4B3XH88jeLh7c08XjrxyjP3zgfO93r3LRmiX85QfPYyCTo/XspbzeM8SaZU0cOj7EigUNHOod4ryWhRw+PkR9KkHLokYguha9Fa5vXIHiMDvSl2bl4qYJn7O/e5A3hPc7EzrCjKVj/RmWL5i54a//dt+LAPz5hnUz9h4i02Xaw93MksA/AFcAB4AnzGybu78w3e81Vl0ywdtWLQbg+svWctmbl3N+y0L+8o/PY+XiJv78B0+x7enXqU8mRl1CYPXSJg50D3LWsnm8dmyAbz78MgCNdQmGhvP81bbnJ+yNfv2B9gnb197Vx/98YC/ZvJNKGL9+4TAfOP8NvHXlQnJ5ODE0TEdPFIznrphP90CGnz8V9Yb7x5wx+/T+Hj5xRzTPflFjiuMlLpNQ7FOXv4W2V7t5qauPzhNp/uSfrqR5YQOrlzbxL9av5sVDx7njkVe48aoLeOyVYwxksrx99RK+uv33I6/xoyf285HWNex6rYeh4RzPdvTyvvNWcMmapTz+6skhqe8/uo9sLk9jXZID3YMsnVfHa8cG2PDWFl492s87zlpKfybLsf4MB7oHcYezl8+jLplgOJdnXn2SvnSWs5bNI53N4x5db78hlcDMyOUdA57t6GVP0XDMU6/18LZVi8lk8zTVJ6lPJkgmjfpkgsPHh+jqS7P+rKUn/z06TzC/IRX91KdIGJxIZ1nUWEd/OksqaTSkovsFFI7RAPQODLN4Xh2ZbJ7OE0Msn99AIsFI3QJ3J5d3UskEubzTOzjM8cFh1q6YD0T3/00lEiQTdsrz+jM5FjSkyOX9lO0FQ8M5GuuS5MK1k1LJk1/EBzJZmuqSJT/Ih4Zz1CcTJEq8bn86ixnMq584GoZzeQxGve/pcHcyufwpv0eZGpvur7JmdhnwJXf/47D+BQB3/7vxntPa2uptbW3T2o5ShoZzPLSnkysufCPDuTw/3dnBQCbLpveeQzqb59Wj/dzym72sa1nIDx9/jS996J9wx29fYdf+HpbOq2PTe8/ltWMDdId57gPDORIGD+2JevULGlJ84+Pr+dYjL/PI3iMj7/vNT7yDXN7ZctdOTufX/cZFjaxYWM9zHZP/BnA63tw8n5e6zvysn/pkglz4heXyTn0yQd6dbN6pTyUqHppKJmxkuuu8+iQJM4ZzedJjnl/40G+qSzI4nKMhlWBBQxRyR/tPDss11iVG6g4NR6+RsOjGMVGgAhiZbI6h4TwLG1MMZHIMhoP0y+fXk8nl6UtnmVeXZH5DalSAD+fyHOnLsGx+Pb2Dw7xhYQNjYzjnzuHjaVoWNTCQzpHNO4ub6siFD5Rj/RlWLGgIH4gnn+cOh44PMa8+GdptzK9PkkxGlQ73psm707KokaP9aRY11lGfSpT8u+0eyJB3pyGVZEFDirqkkc7mSZiRTBiT+IIIQH86Gv5cvbTplP0t1js4TDKRYGg4x4oF9SMfYO7OQCY36v0TdvIx785gJkdTfZLkZBsXHOlL01gX7W/xr6SQo6X+extgZlhhZYzP/NF5fOiiN02pPWb2pLu3ltw2A+H+YeBKd/83Yf0TwLvc/ZNj6m0GNgOcddZZ79i3b9+0tmO6DOfyDKRzLJ5XN26dg72DLGhIkXdY3BTVO9KXZn59iu6BDG9aEg1l9Kez5NxpSCXoOpGmZVEjJ4ayHOodIu9OU32S1UubONqX4dWj/dQloxC5YOVCntzXzZsWN7F0fj3H+jMkzejPZGnv7OPVI/1c/faVHB8cJp3Nc+6K+ZxIZ3m9J2rXa8cGSJixrmUBew/3Mb8hyUAmx7vfvIJ/fOkoXSeGaKpPcvby+Tx7oJfGugTZcKXMt69eTOvZS/n5rg6a6pIcPp6mP/QK8w4tixp47dgAZy2bR9KMnDsvd/WzqDGFmdE9kMEwHKcuGe33oqY6FjWmaKpP0js4zJKmel7vGSSZMBrrkhwfGiaby2NmJCx6biFwk2bUpxIc6UuzZuk83vKGBbxhYSP7uwfYe7iP+lQiBE6CzhNp6pLGQCaHe3QRuMVNdThO0iwKzkUNLGmqpz+TpT+dxT36Dzq/IcXxweGRS1M0pJK885xl7NzXTTbvI73ldS0L6e7P0DMYHXAfGs7hMPJtIxU+WOqSCeqSxtH+DI11UbgkE4a7k87mRy45TXjuvPokmVyeZMJID5f+EEsmjGzeSRgjv+NkwkbCrT+dw0vGDdQlEjTWRR9Q6Wx+JJUWNKZorEty5ESaJfPq6U9no2Mt4T3MGBX0US8/+qaVzUW/d6eyu5+VUkkapRKJ8E3FRj5cCxrrom8ReY8u453P+8i/B0BTXZKhbI6pHvOvS0R/44XnF2d14fOiuKzw3tFj6Tf9V3+whn+2rvQxwonMyXAvdqZ67iIi1aRcuM/EbJkOYE3R+upQJiIiZ8hMhPsTwDozO8fM6oHrgG0z8D4iIjKOaZ8t4+5ZM/sk8CuiqZDfcffnp/t9RERkfDMyz93d7wPum4nXFhGRiVXNGaoiInKSwl1EpAop3EVEqpDCXUSkCk37SUxTaoRZFzDVU1RXAEcmrBUP2pe5p1r2A7Qvc9Xp7MvZ7l7y9NY5Ee6nw8zaxjtDK260L3NPtewHaF/mqpnaFw3LiIhUIYW7iEgVqoZwv322GzCNtC9zT7XsB2hf5qoZ2ZfYj7mLiMipqqHnLiIiYyjcRUSqUKzD3cyuNLM9ZtZuZjfOdnsmYmbfMbNOM3uuqGyZmW03s73hcWkoNzO7NezbM2a2fvZaPpqZrTGzB83sBTN73sw+HcrjuC+NZva4mT0d9uWvQ/k5ZvZYaPOPwuWrMbOGsN4etq+d1R0Yw8ySZvaUmf0irMd1P141s2fNbJeZtYWy2P19AZjZEjO7x8xeNLPdZnbZmdiX2Ia7nbwR91XAhcDHzOzC2W3VhL4HXDmm7EZgh7uvA3aEdYj2a1342QzcdobaWIks8Fl3vxC4FNgSfvdx3Jc0cLm7XwRcDFxpZpcCXwZudve3AN3AplB/E9Adym8O9eaSTwO7i9bjuh8AH3D3i4vmgMfx7wvgFuB+d78AuIjo32fm98XdY/kDXAb8qmj9C8AXZrtdFbR7LfBc0foeYGVYXgnsCcvfBD5Wqt5c+wHuBa6I+74A84CdwLuIzhhMjf1bI7pPwWVhORXq2Wy3PbRndQiKy4FfEN3OM3b7Edr0KrBiTFns/r6AxcArY3+3Z2JfYttzB1YB+4vWD4SyuGlx94Nh+RDQEpZjsX/h6/wlwGPEdF/CUMYuoBPYDrwE9Lh7NlQpbu/IvoTtvcDyM9rg8X0N+BxQuGv0cuK5HxDdU/rXZvakmW0OZXH8+zoH6AK+G4bLvm1m8zkD+xLncK86Hn1Ux2ZuqpktAH4CfMbdjxdvi9O+uHvO3S8m6vm+E7hgdls0eWb2p0Cnuz85222ZJu919/VEwxRbzOx9xRtj9PeVAtYDt7n7JUA/J4dggJnblziHe7XciPuwma0ECI+doXxO75+Z1REF+/fd/aehOJb7UuDuPcCDRMMXS8yscKey4vaO7EvYvhg4emZbWtJ7gA+Z2avAD4mGZm4hfvsBgLt3hMdO4GdEH7px/Ps6ABxw98fC+j1EYT/j+xLncK+WG3FvAzaG5Y1E49eF8uvD0fNLgd6ir3GzyswMuAPY7e5fLdoUx31pNrMlYbmJ6NjBbqKQ/3CoNnZfCvv4YeCB0POaVe7+BXdf7e5rif4vPODuHydm+wFgZvPNbGFhGfgg8Bwx/Pty90PAfjM7PxRtAF7gTOzLbB9wOM2DFVcDvycaI/3ibLengvb+ADgIDBN9om8iGufcAewFfgMsC3WNaDbQS8CzQOtst79oP95L9DXyGWBX+Lk6pvvyduCpsC/PAf85lJ8LPA60Az8GGkJ5Y1hvD9vPne19KLFP7wd+Edf9CG1+Ovw8X/i/Hce/r9C+i4G28Df2c2DpmdgXXX5ARKQKxXlYRkRExqFwFxGpQgp3EZEqpHAXEalCCncRkSqkcBcRqUIKdxGRKvT/ASznCAum2H/wAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(deltas)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8mxqMFNT65F",
        "outputId": "9a460c83-bf49-47db-a766-a91a81fab52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimal degradation for repair= 7.416066407123275\n",
            "cost for repair = 70.06449415256039\n",
            "Time for repair = 22.12639405204461\n"
          ]
        }
      ],
      "source": [
        "optimal_value =[]\n",
        "current_state = 0 #it is new\n",
        "degradation = 0\n",
        "optimal_cost = []\n",
        "expected_optimal_cost=[]\n",
        "num=[]\n",
        "numm =[]\n",
        "\n",
        "        \n",
        "for j in range(2000+1):\n",
        "    #Choose A from S\n",
        "    action = np.argmax(Q[current_state])\n",
        "    if action == 1:\n",
        "        optimal_value.append(degradation) \n",
        "        num.append(j)\n",
        "    \n",
        "    numm =[3*num[i] - 3*num[i-1] for i in range(1, len(num))]\n",
        "    #print(num , numm)\n",
        "    # Take action\n",
        "    current_state, reward ,degradation_new = Envirenment(degradation,action,8)\n",
        "    optimal_cost.append(-reward)\n",
        "    #print (\"degradation =\" + str(degradation), \"action\"+ str(action),\n",
        "          #\"Reward\"+str(reward), \"new degradation =\" + str(degradation_new))\n",
        "    degradation = degradation_new\n",
        "    #print(optimal_cost)\n",
        "    #if any(np.array(optimal_cost) > 50) and any(np.array(optimal_cost) < 550) :\n",
        "        #expected_optimal_cost.append(np.mean(optimal_cost))\n",
        "    if any(np.array(optimal_cost) > 50):\n",
        "        expected_optimal_cost.append(np.mean(optimal_cost))\n",
        "    if action ==1:\n",
        "        optimal_cost = []\n",
        "    \n",
        "    \n",
        "#print(optimal_value)\n",
        "#print(\".................\")\n",
        "#print(expected_optimal_cost)\n",
        "#print(\".................\")\n",
        "print(\"optimal degradation for repair=\",np.mean(optimal_value))\n",
        "#print(\".................\")\n",
        "print(\"cost for repair =\",np.mean(expected_optimal_cost))\n",
        "print(\"Time for repair =\",np.mean(numm))\n",
        "#print(\"Time for repair =\",numm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiJcRWNCT65F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz2l0_KMT65G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "8999327e7e2997f68438cd77e0c9ace3aff82d5b791acf940d464c01e065e5bb"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}